{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"max_rows\", 200)\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "\n",
    "\n",
    "print(\"Import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data => rows: 59400, cols: 40\n",
      "labels data => rows: 59400, cols: 2\n",
      "test data => rows: 14850, cols: 40\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test = pd.read_csv(r\"source/test_features.csv\")\n",
    "\n",
    "# train data\n",
    "train = pd.read_csv(r\"source/train_features.csv\")\n",
    "\n",
    "# target\n",
    "labels = pd.read_csv(r\"source/train_labels.csv\")\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train data => rows: %s, cols: %s\" % (train.shape[0], train.shape[1]))\n",
    "print(\"labels data => rows: %s, cols: %s\" % (labels.shape[0], labels.shape[1]))\n",
    "print(\"test data => rows: %s, cols: %s\" % (test.shape[0], test.shape[1]))\n",
    "\n",
    "assert(train.shape[1] == test.shape[1])\n",
    "\n",
    "# heights column\n",
    "fill_heights = pd.read_csv(r\"source/heights.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates in train dataset: 0\n",
      "duplicates in label dataset: 0\n",
      "duplicates in test dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates in data\n",
    "train_dup_count = np.sum(train.duplicated())\n",
    "label_dup_count = np.sum(labels.duplicated())\n",
    "test_dup_count = np.sum(test.duplicated())\n",
    "\n",
    "print(\"duplicates in train dataset: %s\" % train_dup_count)\n",
    "print(\"duplicates in label dataset: %s\" % label_dup_count)\n",
    "print(\"duplicates in test dataset: %s\" % test_dup_count)\n",
    "\n",
    "assert(train_dup_count == 0 and label_dup_count == 0 and test_dup_count == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make id as index\n",
    "train = train.set_index(\"id\")\n",
    "test = test.set_index(\"id\")\n",
    "labels = labels.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>Germany</td>\n",
       "      <td>998</td>\n",
       "      <td>DWE</td>\n",
       "      <td>35.432732</td>\n",
       "      <td>-10.584159</td>\n",
       "      <td>Kwa John</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Namakinga B</td>\n",
       "      <td>Ruvuma</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Songea Rural</td>\n",
       "      <td>Maposeni</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Mradi wa maji wa maposeni</td>\n",
       "      <td>True</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>481</td>\n",
       "      <td>Government</td>\n",
       "      <td>34.765054</td>\n",
       "      <td>-11.226012</td>\n",
       "      <td>Kwa Mzee Chagala</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Kamba</td>\n",
       "      <td>Ruvuma</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Mbinga</td>\n",
       "      <td>Mbamba bay</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>DANIDA</td>\n",
       "      <td>True</td>\n",
       "      <td>2008</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh date_recorded                  funder  gps_height  \\\n",
       "id                                                                    \n",
       "33492         0.0    2013-02-18                 Germany         998   \n",
       "68707         0.0    2013-02-13  Government Of Tanzania         481   \n",
       "\n",
       "        installer  longitude   latitude          wpt_name  num_private  \\\n",
       "id                                                                       \n",
       "33492         DWE  35.432732 -10.584159          Kwa John            0   \n",
       "68707  Government  34.765054 -11.226012  Kwa Mzee Chagala            0   \n",
       "\n",
       "            basin   subvillage  region  region_code  district_code  \\\n",
       "id                                                                   \n",
       "33492  Lake Nyasa  Namakinga B  Ruvuma           10              2   \n",
       "68707  Lake Nyasa        Kamba  Ruvuma           10              3   \n",
       "\n",
       "                lga        ward  population public_meeting  \\\n",
       "id                                                           \n",
       "33492  Songea Rural    Maposeni         150           True   \n",
       "68707        Mbinga  Mbamba bay          40           True   \n",
       "\n",
       "                   recorded_by scheme_management                scheme_name  \\\n",
       "id                                                                            \n",
       "33492  GeoData Consultants Ltd               VWC  Mradi wa maji wa maposeni   \n",
       "68707  GeoData Consultants Ltd               VWC                     DANIDA   \n",
       "\n",
       "      permit  construction_year extraction_type extraction_type_group  \\\n",
       "id                                                                      \n",
       "33492   True               2009         gravity               gravity   \n",
       "68707   True               2008         gravity               gravity   \n",
       "\n",
       "      extraction_type_class management management_group    payment  \\\n",
       "id                                                                   \n",
       "33492               gravity        vwc       user-group  never pay   \n",
       "68707               gravity        vwc       user-group  never pay   \n",
       "\n",
       "      payment_type water_quality quality_group      quantity quantity_group  \\\n",
       "id                                                                            \n",
       "33492    never pay          soft          good  insufficient   insufficient   \n",
       "68707    never pay          soft          good           dry            dry   \n",
       "\n",
       "       source source_type source_class     waterpoint_type  \\\n",
       "id                                                           \n",
       "33492   river  river/lake      surface  communal standpipe   \n",
       "68707  spring      spring  groundwater  communal standpipe   \n",
       "\n",
       "      waterpoint_type_group  type  \n",
       "id                                 \n",
       "33492    communal standpipe  test  \n",
       "68707    communal standpipe  test  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# differentiate train and test data\n",
    "train[\"type\"] = \"train\"\n",
    "test[\"type\"] = \"test\"\n",
    "\n",
    "# create a data column by merging both train and label set\n",
    "data = pd.concat([train, test], ignore_index=False)\n",
    "\n",
    "assert (data.shape[0] == train.shape[0] + test.shape[0])\n",
    "assert (data.shape[1] == train.shape[1] == test.shape[1])\n",
    "\n",
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `installer` and `funder` columns have too much similar values.\n",
    "They can be grouped together\n",
    "\n",
    "Reference: https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb\n",
    "\n",
    "1. Shrink `installer` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['installer'] = data['installer'].astype(str).str.lower()\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=('fini water', 'fin water', 'finn water', 'finwater', 'finwate'),\n",
    "    value='finw', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace='jaica co', value='jaica', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'district water department', 'district water depar', 'district council',\n",
    "        'district counci', 'village council orpha','kibaha town council',\n",
    "        'village council', 'coun', 'village counil', 'council',\n",
    "        'mbulu district council', 'counc', 'village council .oda',\n",
    "        'sangea district coun', 'songea district coun', 'villege council',\n",
    "        'district  council', 'quick win project /council', 'mbozi district council',\n",
    "        'village  council', 'municipal council', 'tabora municipal council',\n",
    "        'wb / district council'),\n",
    "    value='council', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'rc church', 'rc churc', 'rcchurch/cefa', 'irc', 'rc', 'rc ch', 'hw/rc',\n",
    "        'rc church/central gover', 'kkkt church', 'pentecost church', 'roman church',\n",
    "        'rc/mission', 'rc church/cefa', 'lutheran church', 'tag church',\n",
    "        'free pentecoste church of tanz', 'rc c', 'church', 'rc cathoric',\n",
    "        'morovian church', 'cefa/rc church', 'rc mission', 'anglican church',\n",
    "        'church of disciples', 'anglikana church', 'cetral government /rc',\n",
    "        'pentecostal church', 'cg/rc', 'rc missionary', 'sda church', 'methodist church', 'trc',\n",
    "        'rc msufi', 'haidomu lutheran church', 'baptist church', 'rc church brother',\n",
    "        'st magreth church', 'anglica church', 'global resource co', 'rc mi',\n",
    "        'baptist church of tanzania', 'fpct church', 'rc njoro', 'rc .church',\n",
    "        'rc mis', 'batist church', 'churc', 'dwe/anglican church','missi', 'mission',\n",
    "        'ndanda missions', 'rc/mission', 'cvs miss', 'missionaries', 'hydom luthelani',\n",
    "        'luthe', 'haydom lutheran hospital', 'lutheran', 'missio', 'germany missionary',\n",
    "        'grail mission kiseki bar', 'missionary', 'heri mission', 'german missionsry',\n",
    "        'wamissionari wa kikatoriki', 'neemia mission', 'wamisionari wa kikatoriki'),\n",
    "    value='church', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'central government', 'gove', 'central govt', 'gover', 'cipro/government',\n",
    "        'governme', 'adra /government', 'isf/government', 'adra/government',\n",
    "        'government /tcrs', 'village govt', 'government', 'government /community',\n",
    "        'concern /government', 'goverm', 'village government', 'cental government',\n",
    "        'govern', 'cebtral government', 'government /sda', 'tcrs /government',\n",
    "        'tanzania government', 'centra govt', 'colonial government', 'misri government',\n",
    "        'government and community', 'cetral government /rc', 'concern/government',\n",
    "        'government of misri', 'lwi &central government', 'governmen', 'government/tcrs', 'government /world vision',\n",
    "        'centra government'),\n",
    "    value='tanzanian government', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=('world vission', 'world division', 'word divisio','world visiin'),\n",
    "    value='world vision', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('unicrf', 'unisef'), value='unicef', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'commu', 'olgilai village community', 'adra /community', 'adra/community',\n",
    "        'rwe/ community', 'killflora /community', 'communit', 'taboma/community',\n",
    "        'arab community', 'adra/ community', 'sekei village community', 'rwe/community',\n",
    "        'arabs community', 'village community', 'government /community',\n",
    "        'dads/village community', 'killflora/ community', 'mtuwasa and community',\n",
    "        'rwe /community', 'ilwilo community', 'summit for water/community',\n",
    "        'igolola community', 'ngiresi village community', 'rwe community',\n",
    "        'african realief committe of ku', 'twesa /community', 'shelisheli commission',\n",
    "        'twesa/ community', 'marumbo community', 'government and community',\n",
    "        'community bank', 'kitiangare village community', 'oldadai village community',\n",
    "        'twesa/community', 'tlc/community', 'maseka community', 'islamic community',\n",
    "        'district community j', 'village water commission', 'village community members',\n",
    "        'tcrs/village community', 'village water committee', 'comunity'),\n",
    "    value='community', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=('danid', 'danda','danida co', 'danny', 'daniad', 'dannida', 'danids'),\n",
    "    value='danida', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=('hesaws', 'huches', 'hesaw', 'hesawz', 'hesawq', 'hesewa'),\n",
    "    value='hesawa', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'dwsp', 'kkkt _ konde and dwe', 'rwe/dwe', 'rwedwe', 'dwe/', 'dw', 'dwr',\n",
    "        'dwe}', 'dwt', 'dwe /tassaf', 'dwe/ubalozi wa marekani', 'consultant and dwe',\n",
    "        'dwe & lwi', 'ubalozi wa marekani /dwe', 'dwe&', 'dwe/tassaf', 'dw$',\n",
    "        'dw e', 'tcrs/dwe', 'dw#', 'dweb', 'tcrs /dwe', 'water aid/dwe', 'dww'),\n",
    "    value='dwe', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'africa muslim', 'muslimu society(shia)', 'africa muslim agenc',\n",
    "        'african muslims age', 'muslimehefen international','islamic',\n",
    "        'the isla', 'islamic agency tanzania',  'islam', 'nyabibuye islamic center'),\n",
    "    value='muslims', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'british colonial government', 'british government', 'britain'),\n",
    "    value='british', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'tcrs/tlc', 'tcrs /care', 'cipro/care/tcrs', 'tcrs kibondo', 'tcrs.tlc',\n",
    "        'tcrs /twesa', 'tassaf /tcrs', 'tcrs/care', 'tcrs twesa', 'rwe/tcrs',\n",
    "        'tcrs/twesa', 'tassaf/ tcrs', 'tcrs/ tassaf', 'tcrs/ twesa', 'tcrs a',\n",
    "        'tassaf/tcrs'),\n",
    "    value='tcrs', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'kkkt-dioces ya pare', 'kkkt leguruki', 'kkkt ndrumangeni', 'kkkt dme',\n",
    "        'kkkt kilinga', 'kkkt canal', 'kkkt katiti juu', 'kkkt mareu'),\n",
    "    value='kkkt', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('norad/'), value='norad', inplace=True)\n",
    "\n",
    "data['installer'].replace( to_replace=('tasaf/dmdd', 'dmdd/solider'),value='dmdd', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('cjejow construction', 'cjej0'), value='cjejow', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=('china henan constuction', 'china henan contractor', 'china co.', 'chinese'),\n",
    "    value='china', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'local contract', 'local technician', 'local', 'local  technician',\n",
    "        'locall technician', 'local te', 'local technitian', 'local technical tec',\n",
    "        'local fundi', 'local technical', 'localtechnician', 'village local contractor',\n",
    "        'local l technician'),\n",
    "    value='local', inplace=True)\n",
    "\n",
    "data['installer'].replace(\n",
    "    to_replace=(\n",
    "        'oikos e .africa', 'oikos e.africa', 'africa amini alama',\n",
    "        'africa islamic agency tanzania', 'africare', 'african development foundation',\n",
    "        'oikos e. africa', 'oikos e.afrika', 'afroz ismail', 'africa', 'farm-africa',\n",
    "        'oikos e africa', 'farm africa', 'africaone', 'tina/africare', 'africaone ltd',\n",
    "        'african reflections foundation', 'africa m'),\n",
    "    value='africa', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('h', 'he', 'hsw'), value='hsw', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('jaica', 'jica'), value='jaica', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('lawatefuka water sup', 'losaa-kia water supp'), value='water sup', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('water', 'water aid', 'water board'), value='water', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('region water department', 'sengerema water department'), value='department', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('oxfam', 'oxfarm'), value='oxfarm', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('priva', 'private'), value='private', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('twe', 'twesa'), value='twesa', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('villa', 'villagers'), value='villagers', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('wa', 'wachina', 'wananchi'), value='wa', inplace=True)\n",
    "\n",
    "data['installer'].replace(to_replace=('0', 'nan', '-'), value='other', inplace=True)\n",
    "\n",
    "df_installer_cnt = data.groupby('installer')['installer'].count()\n",
    "other_list = df_installer_cnt[df_installer_cnt<71].index.tolist()\n",
    "data['installer'].replace(to_replace=other_list, value='other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Shrink `funder` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['funder'] = data['funder'].astype(str).str.lower()\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'kkkt_makwale', 'kkkt-dioces ya pare', 'world vision/ kkkt', 'kkkt church',\n",
    "        'kkkt leguruki', 'kkkt ndrumangeni', 'kkkt dme', 'kkkt canal', 'kkkt usa',\n",
    "        'kkkt mareu'),\n",
    "    value='kkkt', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'government of tanzania', 'norad /government', 'government/ community',\n",
    "        'cipro/government', 'isf/government', 'finidagermantanzania govt',\n",
    "        'government /tassaf', 'finida german tanzania govt', 'village government',\n",
    "        'tcrs /government', 'village govt', 'government/ world bank',\n",
    "        'danida /government', 'dhv/gove', 'concern /govern', 'vgovernment',\n",
    "        'lwi & central government', 'government /sda', 'koica and tanzania government',\n",
    "        'world bank/government', 'colonial government', 'misri government',\n",
    "        'government and community', 'concern/governm', 'government of misri',\n",
    "        'government/tassaf', 'government/school', 'government/tcrs', 'unhcr/government',\n",
    "        'government /world vision', 'norad/government', 'ministry of water'),\n",
    "    value='government', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'british colonial government', 'japan government', 'china government',\n",
    "        'finland government', 'belgian government', 'italy government',\n",
    "        'irish government', 'egypt government', 'iran gover', 'swedish', 'finland'),\n",
    "    value='foreign government', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'rc church', 'anglican church', 'rc churc', 'rc ch', 'rcchurch/cefa',\n",
    "        'irc', 'rc', 'churc', 'hw/rc', 'rc church/centr', 'pentecosta church',\n",
    "        'roman church', 'rc/mission', \"ju-sarang church' and bugango\",\n",
    "        'lutheran church', 'roman cathoric church', 'tag church ub', 'aic church',\n",
    "        'free pentecoste church of tanz', 'tag church', 'fpct church', 'rc cathoric',\n",
    "        'baptist church', 'morovian church', 'cefa/rcchurch', 'rc mission',\n",
    "        'bukwang church saints', 'agt church', 'church of disciples', 'rc mofu',\n",
    "        \"gil cafe'church'\", 'pentecostal church', 'bukwang church saint',\n",
    "        'eung am methodist church', 'rc/dwe', 'cg/rc', 'eung-am methodist church',\n",
    "        'rc missionary', 'sda church', 'methodist church', 'rc msufi',\n",
    "        'haidomu lutheran church', 'nazareth church', 'st magreth church',\n",
    "        'agape churc', 'rc missi', 'rc mi', 'rc njoro', 'world vision/rc church',\n",
    "        'pag church', 'batist church', 'full gospel church', 'nazalet church',\n",
    "        'dwe/anglican church', 'missi', 'mission', 'missionaries', 'cpps mission',\n",
    "        'cvs miss', 'grail mission kiseki bar', 'shelisheli commission', 'missionary',\n",
    "        'heri mission', 'german missionary', 'wamissionari wa kikatoriki',\n",
    "        'rc missionary', 'germany missionary', 'missio', 'neemia mission', 'rc missi',\n",
    "        'hydom luthelani', 'luthe', 'lutheran church',  'haydom lutheran hospital',\n",
    "        'village council/ haydom luther', 'lutheran', 'haidomu lutheran church',\n",
    "        'resolute golden pride project', 'resolute mininggolden pride',\n",
    "        'germany cristians'),\n",
    "    value='church', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'olgilai village community', 'commu', 'community', 'arab community',\n",
    "        'sekei village community', 'arabs community', 'village community',\n",
    "        'mtuwasa and community', 'ilwilo community', 'igolola community',\n",
    "        'ngiresi village community', 'marumbo community', 'village communi',\n",
    "        'comune di roma', 'comunity construction fund', 'community bank',\n",
    "        \"oak'zion' and bugango b' commu\", 'kitiangare village community',\n",
    "        'oldadai village community', 'tlc/community', 'maseka community',\n",
    "        'islamic community',  'tcrs/village community', 'buluga subvillage community',\n",
    "        'okutu village community', 'rural water supply and sanitat'),\n",
    "    value='community', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'council', 'wb / district council', 'cdtfdistrict council',\n",
    "        'sangea district council', 'mheza distric counc', 'kyela council',\n",
    "        'kibaha town council', 'swidish', 'mbozi district council',\n",
    "        'village council/ rose kawala',  'songea municipal counci',\n",
    "        'quick win project /council', 'village council', 'villege council',\n",
    "        'tabora municipal council', 'kilindi district co', 'kigoma municipal council',\n",
    "        'district council', 'municipal council', 'district medical',\n",
    "        'sengerema district council', 'town council', 'mkinga  distric cou',\n",
    "        'songea district council', 'district rural project', 'mkinga distric coun',\n",
    "        'dadis'),\n",
    "    value='district', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'tcrs.tlc', 'tcrs /care', 'tcrst', 'cipro/care/tcrs', 'tcrs/care', 'tcrs kibondo'),\n",
    "    value='tcrs', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'fini water', 'finw', 'fin water', 'finn water', 'finwater'),\n",
    "    value='fini', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'islamic', 'the isla', 'islamic found', 'islamic agency tanzania',\n",
    "        'islam', 'muislam', 'the islamic', 'nyabibuye islamic center', 'islamic society', 'african muslim agency',\n",
    "        'muslims', 'answeer muslim grou', 'muslimu society(shia)',\n",
    "        'unicef/african muslim agency', 'muslim world', 'muslimehefen international',\n",
    "        'shear muslim', 'muslim society'),\n",
    "    value='islam', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=('danida', 'ms-danish', 'unhcr/danida', 'tassaf/ danida'),\n",
    "    value='danida', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'hesawa', 'hesawz', 'hesaw', 'hhesawa', 'hesawwa', 'hesawza', 'hesswa',\n",
    "        'hesawa and concern world wide'),\n",
    "    value='hesawa', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=('world vision/adra', 'game division', 'worldvision'),\n",
    "    value='world vision', inplace=True)\n",
    "\n",
    "data['funder'].replace(\n",
    "    to_replace=(\n",
    "        'germany republi', 'a/co germany', 'aco/germany', 'bingo foundation germany',\n",
    "        'africa project ev germany', 'tree ways german'),\n",
    "    value='germany', inplace=True)\n",
    "\n",
    "data['funder'].replace( to_replace=('private', 'private individual'), value='private', inplace=True)\n",
    "\n",
    "data['funder'].replace(to_replace=('ces (gmbh)', 'ces(gmbh)'), value='ces', inplace=True\n",
    ")\n",
    "\n",
    "data['funder'].replace(to_replace=('concern', 'concern world wide'), value='concern', inplace=True\n",
    ")\n",
    "\n",
    "data['funder'].replace(to_replace=('jaica', 'jica'), value='concern', inplace=True)\n",
    "\n",
    "data['funder'].replace(to_replace=('jaica', 'jica'), value='concern', inplace=True)\n",
    "\n",
    "data['funder'].replace(to_replace=('lawatefuka water supply', 'magadini-makiwaru water', 'water', 'wateraid'), value='concern', inplace=True)\n",
    "\n",
    "data['funder'].replace(to_replace=('oxfam', 'oxfarm'), value='oxfarm', inplace=True)\n",
    "\n",
    "data['funder'].replace(to_replace=('0', 'nan', '-'), value='other', inplace=True)\n",
    "df_funder_cnt = data.groupby('funder')['funder'].count()\n",
    "other_list = df_funder_cnt[df_funder_cnt < 98].index.tolist()\n",
    "data['funder'].replace(to_replace=other_list, value='other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sanitizing `null` values\n",
    "\n",
    "1. For boolean columns: -> fill with median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# replace boolean cols with median values\n",
    "data[\"public_meeting\"].fillna(data[\"public_meeting\"].median(), inplace=True)\n",
    "data[\"permit\"].fillna(data[\"permit\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. For string/object values\n",
    "\n",
    "Reference: https://stackoverflow.com/a/60753938/10582056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nan_cols = ['scheme_management']\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value = 'missing')\n",
    "data[nan_cols] = imputer.fit_transform(data[nan_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. For numeric columns\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"amount_tsh\"] = data[\"amount_tsh\"].apply(lambda x: np.log(round(x)) if round(x) > 0 else 0)\n",
    "data[\"population\"] = data[\"population\"].apply(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. For `gps_height`, fill with reference data\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/heights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"gps_height\"].replace(to_replace=0, value=np.nan, inplace=True)\n",
    "data[\"gps_height\"] = data[\"gps_height\"].fillna(fill_heights[\"gps_height\"])\n",
    "data[\"gps_height\"].fillna(value=data[\"gps_height\"].mean(), inplace=True)\n",
    "\n",
    "assert (data[\"gps_height\"].isnull().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Fill missing `latitude` and `longitude` data\n",
    "\n",
    "Because geocode from google requires payment, this alternative is suitable\n",
    "\n",
    "Reference: https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_geo = data.groupby(['region_code'])[['latitude', 'longitude']].median()\n",
    "\n",
    "def geo_update(row, df_geo):\n",
    "    row['longitude'] = df_geo.loc[row['region_code']]['longitude']\n",
    "    row['latitude'] = df_geo.loc[row['region_code']]['latitude']\n",
    "    return row\n",
    "\n",
    "data.loc[data['longitude']== 0, ['longitude', 'latitude']] \\\n",
    "    = data[data['longitude']==0].apply(\n",
    "        geo_update,\n",
    "        df_geo=data_geo,\n",
    "        axis=1)[['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Fill missing `scheme_name`\n",
    "\n",
    "Reference: https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_scheme = data.groupby(['region'])['scheme_name'].agg(pd.Series.mode)\n",
    "\n",
    "def scheme_update(row, df_scheme):\n",
    "    row['scheme_name'] = df_scheme[row['region']]\n",
    "    return row\n",
    "\n",
    "data.loc[data['scheme_name'].isnull(), ['scheme_name']] = \\\n",
    "    data[data['scheme_name'].isnull()].apply(\n",
    "        scheme_update,\n",
    "        df_scheme=data_scheme,\n",
    "        axis=1)[['scheme_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "7. Fill missing `subvillage`\n",
    "\n",
    "Reference: https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_subvillage = data.groupby(['region_code'])['subvillage'].agg(pd.Series.mode)\n",
    "\n",
    "def subvillage_update(row, df_subvillage):\n",
    "    row['subvillage'] = df_subvillage[row['region_code']]\n",
    "    return row\n",
    "\n",
    "data.loc[data['subvillage'].isnull(), ['subvillage']] = \\\n",
    "    data[data['subvillage'].isnull()].apply(\n",
    "        subvillage_update,\n",
    "        df_subvillage=data_subvillage,\n",
    "        axis=1)[['subvillage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with `Latitude` and `Longitude`\n",
    "\n",
    "Reference: https://stackoverflow.com/a/31398615/10582056\n",
    "\n",
    "1. Find the haversine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_lat = data[\"latitude\"].mean()\n",
    "mean_long = data[\"longitude\"].mean()\n",
    "\n",
    "data[\"haversine_distance\"] = data.apply(lambda row: haversine((row[\"latitude\"], row[\"longitude\"]), (mean_lat, mean_long), unit=Unit.KILOMETERS), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert `latitude`, `longitude` to `x_coordinate`, `y_coordinate` and `z_coordinate`\n",
    "\n",
    "Reference: https://heartbeat.fritz.ai/working-with-geospatial-data-in-machine-learning-ad4097c7228d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['x_coordinate'] = np.cos(data['latitude']) * np.cos(data['longitude'])\n",
    "data['y_coordinate'] = np.cos(data['latitude']) * np.sin(data['longitude'])\n",
    "data['z_coordinate'] = np.sin(data['latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do clustering with DBSCAN\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering complete\n"
     ]
    }
   ],
   "source": [
    "db = DBSCAN(eps=0.2, min_samples=200)\n",
    "data[\"location_cluster\"] = db.fit_predict(data[[\"latitude\", \"longitude\"]])\n",
    "\n",
    "print(\"Clustering complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shorten and combine following columns\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this comes at the expense of reduced information\n",
    "# so might be commented out in future if necessary\n",
    "\n",
    "# Shorten and combine\n",
    "cols_100 = [[\"subvillage\", 4, 113],[\"scheme_name\", 5, 65], [\"ward\", 5, 117], [\"wpt_name\", 5, 57]]\n",
    "cols_200 = [[\"subvillage\", 4, 67],[\"scheme_name\", 5, 40], [\"ward\", 5, 87], [\"wpt_name\", 5, 30]]\n",
    "\n",
    "# cols_1000 includes more features at the expense of added complexity\n",
    "cols_1000 = [[\"subvillage\", 10, 11],[\"scheme_name\", 10, 10], [\"ward\", 5, 27], [\"wpt_name\", 10, 7]]\n",
    "combined = \"other\"\n",
    "\n",
    "for col, chars, threshold in cols_100:\n",
    "    # Missing values to combined group\n",
    "    data.loc[data[col].isnull() | data[col].isin([\"0\", \"-\", \"_\"]), col] = col + \"_\" + combined\n",
    "    # Lowercase and shorten\n",
    "    data[col] = data[col].map(lambda x: x[:chars].lower())\n",
    "    # Combine lower than threshold\n",
    "    data.loc[data[col].isin(data[col].value_counts()[data[col].value_counts() < threshold].index), col] = col + \"_\" + combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Drop unnecessary / similar columns\n",
    "\n",
    "Reference:\n",
    "1. https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb\n",
    "2. https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# similar_cols = ['scheme_management', 'quantity_group', 'water_quality',\n",
    "#                 'region_code', 'payment_type', b'extraction_type',\n",
    "#                 'waterpoint_type_group', 'date_recorded', 'recorded_by']\n",
    "\n",
    "similar_cols = ['date_recorded', 'recorded_by', \"latitude\", \"longitude\"]\n",
    "\n",
    "data.drop(similar_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data types in `data` are mixed. So transform\n",
    "\n",
    "1. Some columns are in int format, but they are just categories -> convert them to string\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb\n",
    "\n",
    "2. computable `numeric` and `boolean`(=[`public_meeting`, `permit`]) types to `float64`\n",
    "\n",
    "3. string columns 'category' for quick transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "convert = [\"district_code\", \"construction_year\", \"region_code\", \"location_cluster\", \"num_private\"]\n",
    "for col in convert:\n",
    "    data[col] = data[col].map(lambda x: str(x))\n",
    "\n",
    "# numeric columns\n",
    "numeric_columns = [\"public_meeting\", \"permit\"] + [col for col in data.columns if data[col].dtype not in [object, \"category\"]]\n",
    "\n",
    "# convert to float64\n",
    "for col in numeric_columns:\n",
    "    data[col] = data[col].astype(\"float64\")\n",
    "\n",
    "categorical_columns = [col for col in data.columns if col not in numeric_columns]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check if numeric columns follows Gaussian pattern\n",
    "if true: use `StandardScalar` else use `MinMaxScalar`\n",
    "\n",
    "Reference: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public_meeting: statistics=0.312, p=0.000, no\n",
      "permit: statistics=0.571, p=0.000, no\n",
      "amount_tsh: statistics=0.642, p=0.000, no\n",
      "gps_height: statistics=0.943, p=0.000, no\n",
      "population: statistics=0.783, p=0.000, no\n",
      "haversine_distance: statistics=0.988, p=0.000, no\n",
      "x_coordinate: statistics=0.971, p=0.000, no\n",
      "y_coordinate: statistics=0.967, p=0.000, no\n",
      "z_coordinate: statistics=0.922, p=0.000, no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\OpenSoftware\\miniconda3\\envs\\pump_it_up\\lib\\site-packages\\scipy\\stats\\morestats.py:1760: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "# qqplot(data[\"gps_height\"], line='s')\n",
    "# pyplot.hist(data[\"gps_height\"])\n",
    "# pyplot.show()\n",
    "\n",
    "def is_gaussian(feature, alpha):\n",
    "    stat, p = shapiro(data[feature])\n",
    "    print('%s: statistics=%.3f, p=%.3f, %s' % (feature, stat, p, 'yes' if p > alpha else 'no'))\n",
    "\n",
    "for column in numeric_columns:\n",
    "    is_gaussian(column, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Doing standardisation with `MinMax Scalar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "standard_cols = [\n",
    "    'amount_tsh',\n",
    "    'gps_height',\n",
    "    'population',\n",
    "    'haversine_distance',\n",
    "    'x_coordinate',\n",
    "    'y_coordinate',\n",
    "    'z_coordinate'\n",
    "]\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "data[standard_cols] = scalar.fit_transform(data[standard_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Make all strings to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    data[col] = data[col].apply(lambda x: x.lower(), convert_dtype=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply CatBoost\n",
    "\n",
    "The target labels should be numbers rather than strings. So encode them first\n",
    "\n",
    "Reference: https://stackoverflow.com/a/52061440/10582056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels[\"status_group\"] =  labels[\"status_group\"].astype(\"category\")\n",
    "label_dict = dict(enumerate(labels[\"status_group\"].cat.categories))\n",
    "\n",
    "labels[\"status_group\"] =  labels[\"status_group\"].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "# size = train.shape[0]\n",
    "size = 200\n",
    "\n",
    "target = labels[\"status_group\"].values.ravel()\n",
    "\n",
    "train = data[data.type.eq(\"train\")].drop(\"type\", axis=1)\n",
    "test = data[data.type.eq(\"test\")].drop(\"type\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train.head(size),\n",
    "    target[:size],\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = target[:size],\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "print(\"Good to go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# displaying object column data\n",
    "# both `train` and `test` have same columns\n",
    "\n",
    "# col_details = []\n",
    "# for col in data.columns:\n",
    "#     col_details.append((col, data[col].dtype, data[col].nunique(), list(data[col].unique())))\n",
    "#\n",
    "# col_details.sort(key=lambda x: x[-2])\n",
    "#\n",
    "# temp = pd.DataFrame(col_details, columns=[\"Column\", \"Dtype\", \"N_Unique\", \"Unique_vals\"])\n",
    "# temp\n",
    "\n",
    "\n",
    "# displaying object column data\n",
    "# both `train` and `test` have same columns\n",
    "\n",
    "# col_details = []\n",
    "# for col in train.columns:\n",
    "#     col_details.append((col, train[col].dtype, train[col].nunique(), list(train[col].unique())))\n",
    "#\n",
    "# col_details.sort(key=lambda x: x[-2])\n",
    "#\n",
    "# temp = pd.DataFrame(col_details, columns=[\"Column\", \"Dtype\", \"N_Unique\", \"Unique_vals\"])\n",
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyper parameter tuning for catboost\n",
    "\n",
    "Reference :\n",
    "1. https://stats.stackexchange.com/a/431105\n",
    "2. https://stats.stackexchange.com/a/457445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = [col for col in train.columns if data[col].dtype in (\"category\", object)]\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\":[800, 1000, 1200, 1500, 1700], # iterations\n",
    "    \"max_depth\": [5, 8, 10, 12, 15],\n",
    "    \"learning_rate\": [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7],\n",
    "    \"max_ctr_complexity\": [3, 7, 11, 15], # <16\n",
    "    \"od_wait\": [50, 100, 300, 500, 700, 1000],\n",
    "    \"od_type\": [\"IncToDec\", \"Iter\"],\n",
    "    \"leaf_estimation_backtracking\": ['AnyImprovement'], # Armijo - GPU only\n",
    "    # \"posterior_sampling\": [True, False],\n",
    "    \"auto_class_weights\": [\"Balanced\", \"SqrtBalanced\"],\n",
    "    \"leaf_estimation_method\": [\"Newton\", \"Gradient\"]\n",
    "}\n",
    "\n",
    "# scoring = {\n",
    "#     'accuracy': make_scorer(accuracy_score),\n",
    "#     'precision': make_scorer(precision_score, average = 'macro'),\n",
    "#     'recall': make_scorer(recall_score, average = 'macro'),\n",
    "#     'f1_macro': make_scorer(f1_score, average = 'macro'),\n",
    "#     'f1_weighted': make_scorer(f1_score, average = 'weighted'),\n",
    "#     # 'roc_auc': make_scorer(roc_auc_score, average='macro', multi_class=\"ovo\")\n",
    "#     'QUADRATIC_WEIGHT_SCORER': make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "# }\n",
    "\n",
    "catboost = CatBoostClassifier(\n",
    "    cat_features=cat_features,\n",
    "    task_type=\"GPU\",\n",
    "    random_state=42,\n",
    "    loss_function=\"MultiClass\",\n",
    "    class_names=[0, 1, 2],\n",
    "    allow_writing_files=False,\n",
    "    # thread_count=2,\n",
    "    nan_mode=\"Forbidden\",\n",
    "    fold_permutation_block=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "hrsv = HalvingRandomSearchCV(\n",
    "    estimator=catboost,\n",
    "    param_distributions=grid,\n",
    "    # scoring=make_scorer(cohen_kappa_score, weights='quadratic'),\n",
    "    scoring=make_scorer(f1_score, average = 'weighted'),\n",
    "    # scoring=scoring,\n",
    "    cv=3,\n",
    "    error_score='raise',\n",
    "    refit=False,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hrsv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(hrsv.best_params_)\n",
    "print(hrsv.best_score_)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### for 100 rows\n",
    "\n",
    "{'od_wait': 100, 'od_type': 'IncToDec', 'n_estimators': 1200, 'max_depth': 10, 'max_ctr_complexity': 1, 'learning_rate': 0.5, 'l2_leaf_reg': 5}\n",
    "0.562962962962963\n",
    "\n",
    "{'od_wait': 300, 'od_type': 'IncToDec', 'n_estimators': 1000, 'max_depth': 15, 'max_ctr_complexity': 7, 'learning_rate': 1, 'l2_leaf_reg': 7}\n",
    "0.562962962962963\n",
    "\n",
    "{'od_wait': 300, 'od_type': 'IncToDec', 'n_estimators': 1000, 'max_depth': 15, 'max_ctr_complexity': 7, 'learning_rate': 1, 'l2_leaf_reg': 7}\n",
    "0.5888888888888889\n",
    "\n",
    "{'posterior_sampling': False, 'od_wait': 100, 'od_type': 'IncToDec', 'n_estimators': 1500, 'max_depth': 8, 'max_ctr_complexity': 3, 'learning_rate': 0.1, 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 1}\n",
    "0.6562289562289562\n",
    "\n",
    "{'posterior_sampling': True, 'od_wait': 100, 'od_type': 'Iter', 'n_estimators': 1000, 'max_depth': 8, 'max_ctr_complexity': 15, 'learning_rate': 0.1, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 1, 'auto_class_weights': 'SqrtBalanced'}\n",
    "0.5888888888888889\n",
    "\n",
    "{'posterior_sampling': False, 'od_wait': 1000, 'od_type': 'IncToDec', 'n_estimators': 1700, 'max_depth': 12, 'max_ctr_complexity': 3, 'learning_rate': 0.3, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 5, 'auto_class_weights': 'SqrtBalanced'}\n",
    "0.5577584732407249\n",
    "\n",
    "\n",
    "#### for 25 rows\n",
    "{'posterior_sampling': True, 'od_wait': 100, 'od_type': 'Iter', 'n_estimators': 1000, 'max_depth': 8, 'max_ctr_complexity': 15, 'learning_rate': 0.1, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 3, 'auto_class_weights': 'SqrtBalanced'}\n",
    "0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# catboost = CatBoostClassifier(\n",
    "#     posterior_sampling=False,\n",
    "#     od_wait=1000,\n",
    "#     od_type=\"IncToDec\",\n",
    "#     n_estimators=1700,\n",
    "#     max_depth=12,\n",
    "#     max_ctr_complexity=3,\n",
    "#     learning_rate=0.3,\n",
    "#     leaf_estimation_method=\"Newton\",\n",
    "#     leaf_estimation_backtracking=\"AnyImprovement\",\n",
    "#     l2_leaf_reg=5,\n",
    "#     auto_class_weights='SqrtBalanced'\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}