{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"max_rows\", 200)\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "\n",
    "print(\"Import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility methods to fill missing values for categorical columns\n",
    "\n",
    "Reference: https://github.com/rvt123/Medium_Articles/blob/main/Data_Preprocessing_Reduce_Categories/ARTICLE_MEDIUM_DATA_PREPROCESSING_DECREASE_CATEGORY.ipynb\n",
    "\n",
    "Might try KNN based imputation if this doesn't work"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "outputs": [],
   "source": [
    "def find_index_(df,to_find,col):\n",
    "    min_=1\n",
    "    max_=len(df)\n",
    "    to_find=to_find\n",
    "    while min_<max_:\n",
    "        mid=int((min_+max_)/2)\n",
    "        if(df[1:mid][col].isna().sum()==to_find)and(df[col][(mid-1):mid].isna()).values:\n",
    "            return mid\n",
    "        elif(df[1:mid][col].isna().sum()>to_find)or(df[1:mid][col].isna().sum()==to_find):\n",
    "            max_=mid-1\n",
    "        else:\n",
    "            min_=mid+1\n",
    "        if max_==min_:\n",
    "            if(df[1:min_][col].isna().sum()==to_find)and((df[col][(min_-1):min_].isna()).values):\n",
    "                return min_\n",
    "\n",
    "def replace_cat_list(df,col,cat_list):\n",
    "    count_cat_dict_initial = {'Total_cat':0}\n",
    "    for cat in cat_list:\n",
    "        count_cat_dict_initial[cat] = df.loc[df[col]==cat,col].count()\n",
    "        count_cat_dict_initial['Total_cat'] = count_cat_dict_initial.get('Total_cat') + count_cat_dict_initial[cat]\n",
    "    count_cat_dict_initial['Total'] = len(df[col])\n",
    "    count_cat_dict_final = {'Total_cat':0}\n",
    "    for cat in cat_list[:-1]:\n",
    "        count_cat_dict_final[cat] = int((count_cat_dict_initial.get(cat)/count_cat_dict_initial.get('Total_cat'))*count_cat_dict_initial.get('Total'))\n",
    "        count_cat_dict_final['Total_cat'] = count_cat_dict_final.get('Total_cat') + count_cat_dict_final[cat]\n",
    "    count_cat_dict_final[cat_list[-1]] = count_cat_dict_initial['Total'] - count_cat_dict_final['Total_cat']\n",
    "    fill_dict = {}\n",
    "    for cat in cat_list:\n",
    "        fill_dict[cat] = count_cat_dict_final[cat] - count_cat_dict_initial[cat]\n",
    "    for cat in cat_list[:-1]:\n",
    "        fill_index = find_index_(df,fill_dict.get(cat),col)\n",
    "        df.loc[0:fill_index,col] = df.loc[0:fill_index,col].fillna(cat)\n",
    "    df.loc[:,col] = df.loc[:,col].fillna(cat_list[-1])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data => rows: 59400, cols: 40\n",
      "labels data => rows: 59400, cols: 2\n",
      "test data => rows: 14850, cols: 40\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test = pd.read_csv(r\"source/test_features.csv\")\n",
    "\n",
    "# train data\n",
    "train = pd.read_csv(r\"source/train_features.csv\")\n",
    "\n",
    "# target\n",
    "labels = pd.read_csv(r\"source/train_labels.csv\")\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train data => rows: %s, cols: %s\" % (train.shape[0], train.shape[1]))\n",
    "print(\"labels data => rows: %s, cols: %s\" % (labels.shape[0], labels.shape[1]))\n",
    "print(\"test data => rows: %s, cols: %s\" % (test.shape[0], test.shape[1]))\n",
    "\n",
    "assert(train.shape[1] == test.shape[1])\n",
    "\n",
    "# heights column\n",
    "fill_heights = pd.read_csv(r\"source/heights.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates in train dataset: 0\n",
      "duplicates in label dataset: 0\n",
      "duplicates in test dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates in data\n",
    "train_dup_count = np.sum(train.duplicated())\n",
    "label_dup_count = np.sum(labels.duplicated())\n",
    "test_dup_count = np.sum(test.duplicated())\n",
    "\n",
    "print(\"duplicates in train dataset: %s\" % train_dup_count)\n",
    "print(\"duplicates in label dataset: %s\" % label_dup_count)\n",
    "print(\"duplicates in test dataset: %s\" % test_dup_count)\n",
    "\n",
    "assert(train_dup_count == 0 and label_dup_count == 0 and test_dup_count == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make id as index\n",
    "train = train.set_index(\"id\")\n",
    "test = test.set_index(\"id\")\n",
    "labels = labels.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# differentiate train and test data\n",
    "train[\"type\"] = \"train\"\n",
    "test[\"type\"] = \"test\"\n",
    "\n",
    "# create a data column by merging both train and label set\n",
    "data = pd.concat([train, test], ignore_index=False)\n",
    "\n",
    "# create train and label combo for visualization,\n",
    "# then same transformation can be applied to data\n",
    "visual = pd.merge(train, labels, on='id')\n",
    "\n",
    "# encode status group\n",
    "visual[\"status_group\"] =  visual[\"status_group\"].astype(\"category\")\n",
    "label_dict = dict(enumerate(visual[\"status_group\"].cat.categories))\n",
    "\n",
    "visual[\"status_group_codes\"] =  visual[\"status_group\"].cat.codes\n",
    "\n",
    "assert (data.shape[0] == train.shape[0] + test.shape[0])\n",
    "assert (data.shape[1] == train.shape[1] == test.shape[1])\n",
    "\n",
    "# only train data is here. so drop type\n",
    "visual.drop(\"type\", axis=1, inplace=True)\n",
    "assert (visual.shape[1] == train.shape[1] + labels.shape[1])\n",
    "\n",
    "together = [visual, data]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Order columns by their count of unique values descending order"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "outputs": [
    {
     "data": {
      "text/plain": "0                  wpt_name\n1                subvillage\n2               scheme_name\n3                 installer\n4                      ward\n5                    funder\n6             date_recorded\n7                       lga\n8                    region\n9           extraction_type\n10    extraction_type_group\n11        scheme_management\n12               management\n13                   source\n14                    basin\n15            water_quality\n16    extraction_type_class\n17                  payment\n18             payment_type\n19              source_type\n20          waterpoint_type\n21            quality_group\n22    waterpoint_type_group\n23         management_group\n24                 quantity\n25           quantity_group\n26             source_class\n27             status_group\n28           public_meeting\n29                   permit\n30              recorded_by\nName: Column, dtype: object"
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying object column data\n",
    "# both `train` and `test` have same columns\n",
    "\n",
    "df = visual\n",
    "col_details = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [\"category\", object]:\n",
    "        col_details.append((col, df[col].dtype, df[col].nunique(), list(df[col].unique())))\n",
    "col_details.sort(key=lambda x: 1 / x[-2])\n",
    "\n",
    "temp = pd.DataFrame(col_details, columns=[\"Column\", \"Dtype\", \"N_Unique\", \"Unique_vals\"])\n",
    "temp[\"Column\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will be deleted in future.\n",
    "Just for reference\n",
    "\n",
    "11        scheme_management\n",
    "12               management\n",
    "13                   source\n",
    "14                    basin\n",
    "15            water_quality\n",
    "16    extraction_type_class\n",
    "17                  payment\n",
    "18             payment_type\n",
    "19              source_type\n",
    "20          waterpoint_type\n",
    "21            quality_group\n",
    "22    waterpoint_type_group\n",
    "23         management_group\n",
    "24                 quantity\n",
    "25           quantity_group\n",
    "26             source_class\n",
    "27           public_meeting\n",
    "28                   permit\n",
    "29              recorded_by"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start with `wpt_name` (Name of the waterpoint if there is one)\n",
    "\n",
    "References:\n",
    "1. https://github.com/drivendataorg/pump-it-up/blob/master/kamchatang/Water%20Pump%201%20-%20EDA%20and%20Data%20Cleaning.ipynb\n",
    "2. https://stackoverflow.com/a/58434981/10582056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "outputs": [
    {
     "data": {
      "text/plain": "none                       6.0%\nShuleni                    2.9%\nZahanati                   1.4%\nMsikitini                  0.9%\nKanisani                   0.5%\n                           ... \nKwa Medadi                 0.0%\nKwa Kubembeni              0.0%\nShule Ya Msingi Milanzi    0.0%\nFunua                      0.0%\nKwa Mzee Lugawa            0.0%\nName: wpt_name, Length: 37400, dtype: object"
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"wpt_name\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"wpt_name\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Majority of water points are without names.\n",
    "2. Water points which have names are not significantly dominating\n",
    "\n",
    "Hence this column can be dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [],
   "source": [
    "for df in together:\n",
    "    df.drop(\"wpt_name\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `subvillage` (Geographic location)\n",
    "\n",
    "References:\n",
    "1. https://github.com/drivendataorg/pump-it-up/blob/master/kamchatang/Water%20Pump%201%20-%20EDA%20and%20Data%20Cleaning.ipynb\n",
    "2. https://stackoverflow.com/a/58434981/10582056\n",
    "3. https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [
    {
     "data": {
      "text/plain": "Madukani        0.9%\nShuleni         0.9%\nMajengo         0.8%\nKati            0.6%\nmissing         0.6%\n                ... \nKipompo         0.0%\nChanyamilima    0.0%\nIkalime         0.0%\nKemagaka        0.0%\nKikatanyemba    0.0%\nName: subvillage, Length: 19288, dtype: object"
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"subvillage\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"subvillage\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same as above. Hence this column can be dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "outputs": [],
   "source": [
    "for df in together:\n",
    "    df.drop(\"subvillage\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `scheme_name`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "outputs": [
    {
     "data": {
      "text/plain": "missing                    47.4%\nK                           1.1%\nNone                        1.1%\nBorehole                    0.9%\nChalinze wate               0.7%\n                           ...  \nVisiga water supplly        0.0%\nEmanyata pipelines          0.0%\nMagundi water supply        0.0%\nImalampaka water supply     0.0%\nMtawanya                    0.0%\nName: scheme_name, Length: 2697, dtype: object"
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"scheme_name\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"scheme_name\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. About half of the names are missing\n",
    "1. In rest of them, majority are without names.\n",
    "2. No significantly dominating scheme name is there\n",
    "\n",
    "Hence this column can be dropped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "outputs": [],
   "source": [
    "for df in together:\n",
    "    df.drop(\"scheme_name\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `installer` values can be grouped together\n",
    "\n",
    "Reference:\n",
    "\n",
    "1. https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb\n",
    "2. https://github.com/drivendataorg/pump-it-up/blob/master/kamchatang/Water%20Pump%201%20-%20EDA%20and%20Data%20Cleaning.ipynb\n",
    "3. https://stackoverflow.com/a/58434981/10582056"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in together:\n",
    "    df['installer'] = df['installer'].astype(str).str.lower()\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=('fini water', 'fin water', 'finn water', 'finwater', 'finwate'),\n",
    "        value='finw', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace='jaica co', value='jaica', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'district water department', 'district water depar', 'district council',\n",
    "            'district counci', 'village council orpha','kibaha town council',\n",
    "            'village council', 'coun', 'village counil', 'council',\n",
    "            'mbulu district council', 'counc', 'village council .oda',\n",
    "            'sangea district coun', 'songea district coun', 'villege council',\n",
    "            'district  council', 'quick win project /council', 'mbozi district council',\n",
    "            'village  council', 'municipal council', 'tabora municipal council',\n",
    "            'wb / district council'),\n",
    "        value='council', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'rc church', 'rc churc', 'rcchurch/cefa', 'irc', 'rc', 'rc ch', 'hw/rc',\n",
    "            'rc church/central gover', 'kkkt church', 'pentecost church', 'roman church',\n",
    "            'rc/mission', 'rc church/cefa', 'lutheran church', 'tag church',\n",
    "            'free pentecoste church of tanz', 'rc c', 'church', 'rc cathoric',\n",
    "            'morovian church', 'cefa/rc church', 'rc mission', 'anglican church',\n",
    "            'church of disciples', 'anglikana church', 'cetral government /rc',\n",
    "            'pentecostal church', 'cg/rc', 'rc missionary', 'sda church', 'methodist church', 'trc',\n",
    "            'rc msufi', 'haidomu lutheran church', 'baptist church', 'rc church brother',\n",
    "            'st magreth church', 'anglica church', 'global resource co', 'rc mi',\n",
    "            'baptist church of tanzania', 'fpct church', 'rc njoro', 'rc .church',\n",
    "            'rc mis', 'batist church', 'churc', 'dwe/anglican church','missi', 'mission',\n",
    "            'ndanda missions', 'rc/mission', 'cvs miss', 'missionaries', 'hydom luthelani',\n",
    "            'luthe', 'haydom lutheran hospital', 'lutheran', 'missio', 'germany missionary',\n",
    "            'grail mission kiseki bar', 'missionary', 'heri mission', 'german missionsry',\n",
    "            'wamissionari wa kikatoriki', 'neemia mission', 'wamisionari wa kikatoriki'),\n",
    "        value='church', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'central government', 'gove', 'central govt', 'gover', 'cipro/government',\n",
    "            'governme', 'adra /government', 'isf/government', 'adra/government',\n",
    "            'government /tcrs', 'village govt', 'government', 'government /community',\n",
    "            'concern /government', 'goverm', 'village government', 'cental government',\n",
    "            'govern', 'cebtral government', 'government /sda', 'tcrs /government',\n",
    "            'tanzania government', 'centra govt', 'colonial government', 'misri government',\n",
    "            'government and community', 'cetral government /rc', 'concern/government',\n",
    "            'government of misri', 'lwi &central government', 'governmen', 'government/tcrs', 'government /world vision',\n",
    "            'centra government'),\n",
    "        value='tanzanian government', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=('world vission', 'world division', 'word divisio','world visiin'),\n",
    "        value='world vision', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('unicrf', 'unisef'), value='unicef', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'commu', 'olgilai village community', 'adra /community', 'adra/community',\n",
    "            'rwe/ community', 'killflora /community', 'communit', 'taboma/community',\n",
    "            'arab community', 'adra/ community', 'sekei village community', 'rwe/community',\n",
    "            'arabs community', 'village community', 'government /community',\n",
    "            'dads/village community', 'killflora/ community', 'mtuwasa and community',\n",
    "            'rwe /community', 'ilwilo community', 'summit for water/community',\n",
    "            'igolola community', 'ngiresi village community', 'rwe community',\n",
    "            'african realief committe of ku', 'twesa /community', 'shelisheli commission',\n",
    "            'twesa/ community', 'marumbo community', 'government and community',\n",
    "            'community bank', 'kitiangare village community', 'oldadai village community',\n",
    "            'twesa/community', 'tlc/community', 'maseka community', 'islamic community',\n",
    "            'district community j', 'village water commission', 'village community members',\n",
    "            'tcrs/village community', 'village water committee', 'comunity'),\n",
    "        value='community', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=('danid', 'danda','danida co', 'danny', 'daniad', 'dannida', 'danids'),\n",
    "        value='danida', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=('hesaws', 'huches', 'hesaw', 'hesawz', 'hesawq', 'hesewa'),\n",
    "        value='hesawa', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'dwsp', 'kkkt _ konde and dwe', 'rwe/dwe', 'rwedwe', 'dwe/', 'dw', 'dwr',\n",
    "            'dwe}', 'dwt', 'dwe /tassaf', 'dwe/ubalozi wa marekani', 'consultant and dwe',\n",
    "            'dwe & lwi', 'ubalozi wa marekani /dwe', 'dwe&', 'dwe/tassaf', 'dw$',\n",
    "            'dw e', 'tcrs/dwe', 'dw#', 'dweb', 'tcrs /dwe', 'water aid/dwe', 'dww'),\n",
    "        value='dwe', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'africa muslim', 'muslimu society(shia)', 'africa muslim agenc',\n",
    "            'african muslims age', 'muslimehefen international','islamic',\n",
    "            'the isla', 'islamic agency tanzania',  'islam', 'nyabibuye islamic center'),\n",
    "        value='muslims', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'british colonial government', 'british government', 'britain'),\n",
    "        value='british', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'tcrs/tlc', 'tcrs /care', 'cipro/care/tcrs', 'tcrs kibondo', 'tcrs.tlc',\n",
    "            'tcrs /twesa', 'tassaf /tcrs', 'tcrs/care', 'tcrs twesa', 'rwe/tcrs',\n",
    "            'tcrs/twesa', 'tassaf/ tcrs', 'tcrs/ tassaf', 'tcrs/ twesa', 'tcrs a',\n",
    "            'tassaf/tcrs'),\n",
    "        value='tcrs', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'kkkt-dioces ya pare', 'kkkt leguruki', 'kkkt ndrumangeni', 'kkkt dme',\n",
    "            'kkkt kilinga', 'kkkt canal', 'kkkt katiti juu', 'kkkt mareu'),\n",
    "        value='kkkt', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('norad/'), value='norad', inplace=True)\n",
    "\n",
    "    df['installer'].replace( to_replace=('tasaf/dmdd', 'dmdd/solider'),value='dmdd', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('cjejow construction', 'cjej0'), value='cjejow', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=('china henan constuction', 'china henan contractor', 'china co.', 'chinese'),\n",
    "        value='china', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'local contract', 'local technician', 'local', 'local  technician',\n",
    "            'locall technician', 'local te', 'local technitian', 'local technical tec',\n",
    "            'local fundi', 'local technical', 'localtechnician', 'village local contractor',\n",
    "            'local l technician'),\n",
    "        value='local', inplace=True)\n",
    "\n",
    "    df['installer'].replace(\n",
    "        to_replace=(\n",
    "            'oikos e .africa', 'oikos e.africa', 'africa amini alama',\n",
    "            'africa islamic agency tanzania', 'africare', 'african development foundation',\n",
    "            'oikos e. africa', 'oikos e.afrika', 'afroz ismail', 'africa', 'farm-africa',\n",
    "            'oikos e africa', 'farm africa', 'africaone', 'tina/africare', 'africaone ltd',\n",
    "            'african reflections foundation', 'africa m'),\n",
    "        value='africa', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('h', 'he', 'hsw'), value='hsw', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('jaica', 'jica'), value='jaica', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('lawatefuka water sup', 'losaa-kia water supp'), value='water sup', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('water', 'water aid', 'water board'), value='water', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('region water department', 'sengerema water department'), value='department', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('oxfam', 'oxfarm'), value='oxfarm', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('priva', 'private'), value='private', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('twe', 'twesa'), value='twesa', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('villa', 'villagers'), value='villagers', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('wa', 'wachina', 'wananchi'), value='wa', inplace=True)\n",
    "\n",
    "    df['installer'].replace(to_replace=('0', 'nan', '-', '_'), value='missing', inplace=True)\n",
    "\n",
    "    df_installer_cnt = df.groupby('installer')['installer'].count()\n",
    "    other_list = df_installer_cnt[df_installer_cnt<71].index.tolist()\n",
    "    df['installer'].replace(to_replace=other_list, value='other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "outputs": [
    {
     "data": {
      "text/plain": "dwe                              30.5%\nother                            14.2%\nmissing                           7.5%\ntanzanian government              6.2%\ncommunity                         3.3%\ndanida                            2.8%\nhesawa                            2.4%\ncouncil                           2.3%\nrwe                               2.0%\nchurch                            1.6%\nkkkt                              1.6%\nfinw                              1.3%\ntcrs                              1.2%\nworld vision                      1.2%\nces                               1.0%\namref                             0.7%\ntwesa                             0.7%\nlga                               0.7%\ntasaf                             0.7%\nwedeco                            0.7%\ndmdd                              0.7%\njaica                             0.6%\nnorad                             0.6%\nunicef                            0.6%\noxfarm                            0.6%\nhsw                               0.5%\nda                                0.5%\nwater                             0.5%\nwu                                0.5%\ndepartment                        0.5%\nvillagers                         0.5%\nwa                                0.5%\nacra                              0.5%\nsema                              0.4%\nwater sup                         0.4%\nshipo                             0.4%\nlocal                             0.4%\nidara ya maji                     0.4%\nprivate                           0.4%\nkiliwater                         0.4%\ndh                                0.3%\nkuwait                            0.3%\ndistri                            0.3%\nmagadini-makiwaru wa              0.3%\nfw                                0.3%\ncentr                             0.3%\nwvt                               0.3%\nmwe                               0.3%\nis                                0.3%\nhandeni trunk main(               0.3%\nworld bank                        0.3%\nrwssp                             0.3%\nisf                               0.2%\nadra                              0.2%\nartisan                           0.2%\nddca                              0.2%\nworld                             0.2%\nafrica                            0.2%\ntardo                             0.2%\nir                                0.2%\nconsulting engineer               0.2%\nmuwsa                             0.2%\nded                               0.2%\nwizara ya maji                    0.2%\nhalmashauri ya wilaya sikonge     0.2%\ngo                                0.2%\nki                                0.2%\nangli                             0.2%\nroman                             0.2%\nvwc                               0.2%\ncefa                              0.2%\naict                              0.1%\nmdrdp                             0.1%\nchamavita                         0.1%\nlwi                               0.1%\nName: installer, dtype: object"
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"installer\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"installer\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the result, it can be seen that following values dominate\n",
    "1. dwe\n",
    "2. other\n",
    "3. tanzanian government\n",
    "4. community\n",
    "5. danida\n",
    "6. hesawa\n",
    "7. council\n",
    "8. rwe\n",
    "9. church\n",
    "10. kkkt\n",
    "\n",
    "There is also significant amount of `missing`: 7.5 %\n",
    "\n",
    "So now reduce the total categories to these 11 values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "outputs": [],
   "source": [
    "selected = ['dwe', 'tanzanian government', 'community', 'danida', 'hesawa', 'council', 'rwe', 'church', 'kkkt', 'missing']\n",
    "\n",
    "def truncate(row):\n",
    "    if row not in selected:\n",
    "        return \"other\"\n",
    "\n",
    "for df in together:\n",
    "    df[\"installer\"] = df.apply(lambda row: \"other\" if row[\"installer\"] not in selected else row[\"installer\"], axis=1)\n",
    "\n",
    "# apply impute missing values\n",
    "selected.remove(\"missing\")\n",
    "\n",
    "for df in together:\n",
    "    df[\"installer\"].replace(to_replace=\"missing\", value=np.nan, inplace=True)\n",
    "    df = replace_cat_list(df,'installer', selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              status_group_codes\ninstaller            status_group                               \nchurch               functional                              670\n                     functional needs repair                  66\n                     non functional                          227\ncommunity            functional                             1291\n                     functional needs repair                  94\n                     non functional                          591\ncouncil              functional                              543\n                     functional needs repair                  93\n                     non functional                          726\ndanida               functional                             1041\n                     functional needs repair                  95\n                     non functional                          545\ndwe                  functional                            11906\n                     functional needs repair                1987\n                     non functional                         7961\nhesawa               functional                              792\n                     functional needs repair                  54\n                     non functional                          557\nkkkt                 functional                              807\n                     functional needs repair                 149\n                     non functional                          669\nother                functional                            13638\n                     functional needs repair                1318\n                     non functional                         8673\nrwe                  functional                              304\n                     functional needs repair                 137\n                     non functional                          765\ntanzanian government functional                             1267\n                     functional needs repair                 324\n                     non functional                         2110",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>status_group_codes</th>\n    </tr>\n    <tr>\n      <th>installer</th>\n      <th>status_group</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">church</th>\n      <th>functional</th>\n      <td>670</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>227</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">community</th>\n      <th>functional</th>\n      <td>1291</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>591</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">council</th>\n      <th>functional</th>\n      <td>543</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>726</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">danida</th>\n      <th>functional</th>\n      <td>1041</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>545</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">dwe</th>\n      <th>functional</th>\n      <td>11906</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>1987</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>7961</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">hesawa</th>\n      <th>functional</th>\n      <td>792</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>557</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">kkkt</th>\n      <th>functional</th>\n      <td>807</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>669</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">other</th>\n      <th>functional</th>\n      <td>13638</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>1318</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>8673</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">rwe</th>\n      <th>functional</th>\n      <td>304</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>765</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">tanzanian government</th>\n      <th>functional</th>\n      <td>1267</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>324</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>2110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv_table = pd.pivot_table(visual,index=['installer','status_group'], values='status_group_codes', aggfunc='count')\n",
    "piv_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a clear distinction between values in `installer` and result\n",
    "\n",
    "Next is `ward`(Geographic location)`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "outputs": [],
   "source": [
    "visual[\"ward\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"ward\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "\n",
    "# `ward` has no significant values. Hence this column can be dropped\n",
    "\n",
    "for df in together:\n",
    "    df.drop(\"ward\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `funder` values can be grouped together\n",
    "\n",
    "Reference:\n",
    "1. https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb\n",
    "2. https://github.com/drivendataorg/pump-it-up/blob/master/kamchatang/Water%20Pump%201%20-%20EDA%20and%20Data%20Cleaning.ipynb\n",
    "3. https://stackoverflow.com/a/58434981/10582056"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in together:\n",
    "    df['funder'] = df['funder'].astype(str).str.lower()\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'kkkt_makwale', 'kkkt-dioces ya pare', 'world vision/ kkkt', 'kkkt church',\n",
    "            'kkkt leguruki', 'kkkt ndrumangeni', 'kkkt dme', 'kkkt canal', 'kkkt usa',\n",
    "            'kkkt mareu'),\n",
    "        value='kkkt', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'government of tanzania', 'norad /government', 'government/ community',\n",
    "            'cipro/government', 'isf/government', 'finidagermantanzania govt',\n",
    "            'government /tassaf', 'finida german tanzania govt', 'village government',\n",
    "            'tcrs /government', 'village govt', 'government/ world bank',\n",
    "            'danida /government', 'dhv/gove', 'concern /govern', 'vgovernment',\n",
    "            'lwi & central government', 'government /sda', 'koica and tanzania government',\n",
    "            'world bank/government', 'colonial government', 'misri government',\n",
    "            'government and community', 'concern/governm', 'government of misri',\n",
    "            'government/tassaf', 'government/school', 'government/tcrs', 'unhcr/government',\n",
    "            'government /world vision', 'norad/government', 'ministry of water'),\n",
    "        value='government', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'british colonial government', 'japan government', 'china government',\n",
    "            'finland government', 'belgian government', 'italy government',\n",
    "            'irish government', 'egypt government', 'iran gover', 'swedish', 'finland'),\n",
    "        value='foreign government', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'rc church', 'anglican church', 'rc churc', 'rc ch', 'rcchurch/cefa',\n",
    "            'irc', 'rc', 'churc', 'hw/rc', 'rc church/centr', 'pentecosta church',\n",
    "            'roman church', 'rc/mission', \"ju-sarang church' and bugango\",\n",
    "            'lutheran church', 'roman cathoric church', 'tag church ub', 'aic church',\n",
    "            'free pentecoste church of tanz', 'tag church', 'fpct church', 'rc cathoric',\n",
    "            'baptist church', 'morovian church', 'cefa/rcchurch', 'rc mission',\n",
    "            'bukwang church saints', 'agt church', 'church of disciples', 'rc mofu',\n",
    "            \"gil cafe'church'\", 'pentecostal church', 'bukwang church saint',\n",
    "            'eung am methodist church', 'rc/dwe', 'cg/rc', 'eung-am methodist church',\n",
    "            'rc missionary', 'sda church', 'methodist church', 'rc msufi',\n",
    "            'haidomu lutheran church', 'nazareth church', 'st magreth church',\n",
    "            'agape churc', 'rc missi', 'rc mi', 'rc njoro', 'world vision/rc church',\n",
    "            'pag church', 'batist church', 'full gospel church', 'nazalet church',\n",
    "            'dwe/anglican church', 'missi', 'mission', 'missionaries', 'cpps mission',\n",
    "            'cvs miss', 'grail mission kiseki bar', 'shelisheli commission', 'missionary',\n",
    "            'heri mission', 'german missionary', 'wamissionari wa kikatoriki',\n",
    "            'rc missionary', 'germany missionary', 'missio', 'neemia mission', 'rc missi',\n",
    "            'hydom luthelani', 'luthe', 'lutheran church',  'haydom lutheran hospital',\n",
    "            'village council/ haydom luther', 'lutheran', 'haidomu lutheran church',\n",
    "            'resolute golden pride project', 'resolute mininggolden pride',\n",
    "            'germany cristians'),\n",
    "        value='church', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'olgilai village community', 'commu', 'community', 'arab community',\n",
    "            'sekei village community', 'arabs community', 'village community',\n",
    "            'mtuwasa and community', 'ilwilo community', 'igolola community',\n",
    "            'ngiresi village community', 'marumbo community', 'village communi',\n",
    "            'comune di roma', 'comunity construction fund', 'community bank',\n",
    "            \"oak'zion' and bugango b' commu\", 'kitiangare village community',\n",
    "            'oldadai village community', 'tlc/community', 'maseka community',\n",
    "            'islamic community',  'tcrs/village community', 'buluga subvillage community',\n",
    "            'okutu village community', 'rural water supply and sanitat'),\n",
    "        value='community', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'council', 'wb / district council', 'cdtfdistrict council',\n",
    "            'sangea district council', 'mheza distric counc', 'kyela council',\n",
    "            'kibaha town council', 'swidish', 'mbozi district council',\n",
    "            'village council/ rose kawala',  'songea municipal counci',\n",
    "            'quick win project /council', 'village council', 'villege council',\n",
    "            'tabora municipal council', 'kilindi district co', 'kigoma municipal council',\n",
    "            'district council', 'municipal council', 'district medical',\n",
    "            'sengerema district council', 'town council', 'mkinga  distric cou',\n",
    "            'songea district council', 'district rural project', 'mkinga distric coun',\n",
    "            'dadis'),\n",
    "        value='district', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'tcrs.tlc', 'tcrs /care', 'tcrst', 'cipro/care/tcrs', 'tcrs/care', 'tcrs kibondo'),\n",
    "        value='tcrs', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'fini water', 'finw', 'fin water', 'finn water', 'finwater'),\n",
    "        value='fini', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'islamic', 'the isla', 'islamic found', 'islamic agency tanzania',\n",
    "            'islam', 'muislam', 'the islamic', 'nyabibuye islamic center', 'islamic society', 'african muslim agency',\n",
    "            'muslims', 'answeer muslim grou', 'muslimu society(shia)',\n",
    "            'unicef/african muslim agency', 'muslim world', 'muslimehefen international',\n",
    "            'shear muslim', 'muslim society'),\n",
    "        value='islam', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=('danida', 'ms-danish', 'unhcr/danida', 'tassaf/ danida'),\n",
    "        value='danida', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'hesawa', 'hesawz', 'hesaw', 'hhesawa', 'hesawwa', 'hesawza', 'hesswa',\n",
    "            'hesawa and concern world wide'),\n",
    "        value='hesawa', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=('world vision/adra', 'game division', 'worldvision'),\n",
    "        value='world vision', inplace=True)\n",
    "\n",
    "    df['funder'].replace(\n",
    "        to_replace=(\n",
    "            'germany republi', 'a/co germany', 'aco/germany', 'bingo foundation germany',\n",
    "            'africa project ev germany', 'tree ways german'),\n",
    "        value='germany', inplace=True)\n",
    "\n",
    "    df['funder'].replace( to_replace=('private', 'private individual'), value='private', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('ces (gmbh)', 'ces(gmbh)'), value='ces', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('concern', 'concern world wide'), value='concern', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('jaica', 'jica'), value='concern', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('jaica', 'jica'), value='concern', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('lawatefuka water supply', 'magadini-makiwaru water', 'water', 'wateraid'), value='concern', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('oxfam', 'oxfarm'), value='oxfarm', inplace=True)\n",
    "\n",
    "    df['funder'].replace(to_replace=('0', 'nan', '-', '_'), value='missing', inplace=True)\n",
    "    df_funder_cnt = df.groupby('funder')['funder'].count()\n",
    "    other_list = df_funder_cnt[df_funder_cnt < 98].index.tolist()\n",
    "    df['funder'].replace(to_replace=other_list, value='other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [
    {
     "data": {
      "text/plain": "other                            17.8%\ngovernment                       16.7%\nmissing                           7.4%\ndanida                            5.3%\nhesawa                            3.7%\nconcern                           3.5%\nkkkt                              2.6%\ndistrict                          2.5%\nchurch                            2.5%\nrwssp                             2.3%\nworld bank                        2.3%\nworld vision                      2.1%\nprivate                           1.9%\nunicef                            1.8%\ntasaf                             1.5%\ndhv                               1.4%\ndwsp                              1.4%\nnorad                             1.3%\nfini                              1.3%\ngermany                           1.2%\ntcrs                              1.0%\ncommunity                         0.9%\noxfarm                            0.9%\ndwe                               0.8%\nnetherlands                       0.8%\nhifab                             0.8%\nadb                               0.8%\nlga                               0.7%\namref                             0.7%\nces                               0.7%\nisf                               0.5%\nrudep                             0.5%\nroman                             0.5%\nadra                              0.4%\nshipo                             0.4%\nforeign government                0.4%\nwsdp                              0.4%\ndh                                0.4%\nded                               0.3%\nplan int                          0.3%\nkiliwater                         0.3%\ndmdd                              0.3%\ngo                                0.3%\nfw                                0.3%\nw.b                               0.3%\nwvt                               0.3%\noikos e.afrika                    0.3%\nnethalan                          0.3%\nlvia                              0.2%\nunhcr                             0.2%\nno                                0.2%\nafrican                           0.2%\nis                                0.2%\nhe                                0.2%\nki                                0.2%\ntardo                             0.2%\nir                                0.2%\nwananchi                          0.2%\nsnv                               0.2%\nroman catholic                    0.2%\nwua                               0.2%\nunice                             0.2%\nbsf                               0.2%\ntassaf                            0.2%\nislam                             0.2%\nco                                0.2%\ndfid                              0.2%\nlamp                              0.2%\nmuwsa                             0.2%\nvillagers                         0.2%\nru                                0.2%\nhalmashauri ya wilaya sikonge     0.2%\nhsw                               0.2%\nName: funder, dtype: object"
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"funder\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"funder\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the result, it can be seen that following values dominate\n",
    "1. other                            25.2%\n",
    "2. government                       16.7%\n",
    "3. danida                            5.3%\n",
    "4. hesawa                            3.7%\n",
    "5. concern                           3.5%\n",
    "6. kkkt                              2.6%\n",
    "7. district                          2.5%\n",
    "8. church                            2.5%\n",
    "9. rwssp                             2.3%\n",
    "10. world bank                        2.3%\n",
    "11. world vision                      2.1%\n",
    "\n",
    "There is also significant amount of `missing`: 7.4 %\n",
    "\n",
    "So now reduce the total categories to these 11 values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [],
   "source": [
    "selected = ['government', 'danida', 'hesawa', 'hesawa', 'concern',\n",
    "            'kkkt', 'district', 'church', 'rwssp', 'world bank',\n",
    "            'world vision', 'missing']\n",
    "\n",
    "def truncate(row):\n",
    "    if row not in selected:\n",
    "        return \"other\"\n",
    "\n",
    "for df in together:\n",
    "    df[\"funder\"] = df.apply(lambda row: \"other\" if row[\"funder\"] not in selected else row[\"funder\"], axis=1)\n",
    "\n",
    "# apply impute missing values\n",
    "selected.remove(\"missing\")\n",
    "\n",
    "for df in together:\n",
    "    df[\"funder\"].replace(to_replace=\"missing\", value=np.nan, inplace=True)\n",
    "    df = replace_cat_list(df,'funder', selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      status_group_codes\nfunder       status_group                               \nchurch       functional                             1112\n             functional needs repair                  73\n             non functional                          274\nconcern      functional                             1366\n             functional needs repair                 134\n             non functional                          563\ndanida       functional                             1721\n             functional needs repair                 159\n             non functional                         1242\ndistrict     functional                              805\n             functional needs repair                  63\n             non functional                          620\ngovernment   functional                             6080\n             functional needs repair                1106\n             non functional                         6441\nhesawa       functional                              943\n             functional needs repair                 232\n             non functional                         1042\nkkkt         functional                              871\n             functional needs repair                  82\n             non functional                          593\nother        functional                            16892\n             functional needs repair                2046\n             non functional                        10247\nrwssp        functional                              805\n             functional needs repair                 109\n             non functional                          460\nworld bank   functional                              545\n             functional needs repair                  97\n             non functional                          707\nworld vision functional                             1119\n             functional needs repair                 216\n             non functional                          635",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>status_group_codes</th>\n    </tr>\n    <tr>\n      <th>funder</th>\n      <th>status_group</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">church</th>\n      <th>functional</th>\n      <td>1112</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">concern</th>\n      <th>functional</th>\n      <td>1366</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>563</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">danida</th>\n      <th>functional</th>\n      <td>1721</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>159</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>1242</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">district</th>\n      <th>functional</th>\n      <td>805</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">government</th>\n      <th>functional</th>\n      <td>6080</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>1106</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>6441</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">hesawa</th>\n      <th>functional</th>\n      <td>943</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>1042</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">kkkt</th>\n      <th>functional</th>\n      <td>871</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">other</th>\n      <th>functional</th>\n      <td>16892</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>2046</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>10247</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">rwssp</th>\n      <th>functional</th>\n      <td>805</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>109</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>460</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">world bank</th>\n      <th>functional</th>\n      <td>545</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>707</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">world vision</th>\n      <th>functional</th>\n      <td>1119</td>\n    </tr>\n    <tr>\n      <th>functional needs repair</th>\n      <td>216</td>\n    </tr>\n    <tr>\n      <th>non functional</th>\n      <td>635</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv_table = pd.pivot_table(visual, index=['funder','status_group'], values='status_group_codes', aggfunc='count')\n",
    "piv_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next is `date_recorded` (The date the row was entered)\n",
    "\n",
    "The column can be converted to date object. Then `year`\n",
    "can be extracted from it and the `age` of each pump can be calculated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [
    {
     "data": {
      "text/plain": "count          59400\nunique           356\ntop       2011-03-15\nfreq             572\nName: date_recorded, dtype: object"
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"date_recorded\"].describe()\n",
    "\n",
    "# date is in format: 2011-03-15 year-month-date\n",
    "# extract year from this column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "outputs": [],
   "source": [
    "def calculate_age(row):\n",
    "    date_recorded = datetime.datetime.strptime(str(row['date_recorded']), '%Y-%m-%d')\n",
    "    year_recorded = int(date_recorded.strftime('%Y'))\n",
    "    construction_year = row['construction_year']\n",
    "    if year_recorded > construction_year > 0:\n",
    "        return np.abs(year_recorded - construction_year)\n",
    "    else: return np.nan\n",
    "\n",
    "\n",
    "for df in together:\n",
    "    df[\"age\"] = df.apply(calculate_age, axis=1)\n",
    "\n",
    "# note that `age` has nan values which have to be filled later\n",
    "\n",
    "# now drop `date_recorded`\n",
    "for df in together:\n",
    "    df.drop(\"date_recorded\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`construction_year` can be binned\n",
    "\n",
    "Reference: https://github.com/drivendataorg/pump-it-up/blob/master/kamchatang/Water%20Pump%201%20-%20EDA%20and%20Data%20Cleaning.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MSIUSE~1\\AppData\\Local\\Temp/ipykernel_1848/1931585743.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;31m# apply impute missing values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtogether\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'construction_year'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mconstruction_wrangler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[1;31m# df[\"construction_year\"].replace(to_replace=\"missing\", value=np.nan, inplace=True)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;31m# df = replace_cat_list(df,'construction_year', selected)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OpenSoftware\\miniconda3\\envs\\pump_it_up\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   8734\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8735\u001B[0m         )\n\u001B[1;32m-> 8736\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   8737\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8738\u001B[0m     def applymap(\n",
      "\u001B[1;32mE:\\OpenSoftware\\miniconda3\\envs\\pump_it_up\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    686\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 688\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    689\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    690\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OpenSoftware\\miniconda3\\envs\\pump_it_up\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    811\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 812\u001B[1;33m         \u001B[0mresults\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    813\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    814\u001B[0m         \u001B[1;31m# wrap results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OpenSoftware\\miniconda3\\envs\\pump_it_up\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    826\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m                 \u001B[1;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 828\u001B[1;33m                 \u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    829\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    830\u001B[0m                     \u001B[1;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MSIUSE~1\\AppData\\Local\\Temp/ipykernel_1848/1931585743.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;31m# apply impute missing values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtogether\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'construction_year'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mconstruction_wrangler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[1;31m# df[\"construction_year\"].replace(to_replace=\"missing\", value=np.nan, inplace=True)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;31m# df = replace_cat_list(df,'construction_year', selected)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MSIUSE~1\\AppData\\Local\\Temp/ipykernel_1848/1931585743.py\u001B[0m in \u001B[0;36mconstruction_wrangler\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mconstruction_wrangler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[1;36m1960\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'construction_year'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1970\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;34m'60s'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[1;36m1970\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'construction_year'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1980\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;34m'70s'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '<=' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "def construction_wrangler(row):\n",
    "    if 1960 <= row['construction_year'] < 1970:\n",
    "        return '60s'\n",
    "    elif 1970 <= row['construction_year'] < 1980:\n",
    "        return '70s'\n",
    "    elif 1980 <= row['construction_year'] < 1990:\n",
    "        return '80s'\n",
    "    elif 1990 <= row['construction_year'] < 2000:\n",
    "        return '90s'\n",
    "    elif 2000 <= row['construction_year'] < 2010:\n",
    "        return '00s'\n",
    "    elif row['construction_year'] >= 2010:\n",
    "        return '10s'\n",
    "    else:\n",
    "        return \"missing\"\n",
    "\n",
    "selected = [\"60s\", \"70s\", \"80s\", \"90s\", \"00s\", \"10s\"]\n",
    "\n",
    "# apply impute missing values\n",
    "for df in together:\n",
    "    df['construction_year'] = df.apply(lambda row: construction_wrangler(row), axis=1)\n",
    "    # df[\"construction_year\"].replace(to_replace=\"missing\", value=np.nan, inplace=True)\n",
    "    # df = replace_cat_list(df,'construction_year', selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next is `region` and `lga`.\n",
    "\n",
    "There is not one dominating value in here. So drop these columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "outputs": [
    {
     "data": {
      "text/plain": "Iringa           8.9%\nShinyanga        8.4%\nMbeya            7.8%\nKilimanjaro      7.4%\nMorogoro         6.7%\nArusha           5.6%\nKagera           5.6%\nMwanza           5.2%\nKigoma           4.7%\nRuvuma           4.4%\nPwani            4.4%\nTanga            4.3%\nDodoma           3.7%\nSingida          3.5%\nMara             3.3%\nTabora           3.3%\nRukwa            3.0%\nMtwara           2.9%\nManyara          2.7%\nLindi            2.6%\nDar es Salaam    1.4%\nName: region, dtype: object"
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"region\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"region\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "outputs": [
    {
     "data": {
      "text/plain": "Njombe              4.2%\nMoshi Rural         2.1%\nArusha Rural        2.0%\nBariadi             2.0%\nRungwe              1.9%\nKilosa              1.8%\nKasulu              1.8%\nMbozi               1.7%\nBagamoyo            1.7%\nMeru                1.7%\nKilombero           1.6%\nSingida Rural       1.6%\nSame                1.5%\nKibondo             1.5%\nKyela               1.4%\nKahama              1.4%\nMagu                1.4%\nMaswa               1.4%\nKigoma Rural        1.4%\nKaragwe             1.3%\nMbinga              1.3%\nIringa Rural        1.2%\nSerengeti           1.2%\nSongea Rural        1.2%\nLushoto             1.2%\nNgara               1.2%\nMpanda              1.1%\nMvomero             1.1%\nNamtumbo            1.1%\nUlanga              1.1%\nMakete              1.1%\nKwimba              1.1%\nMbarali             1.1%\nHai                 1.1%\nShinyanga Rural     1.0%\nRombo               1.0%\nNzega               1.0%\nMkuranga            0.9%\nLudewa              0.9%\nIramba              0.9%\nMorogoro Rural      0.9%\nBukombe             0.9%\nMasasi              0.9%\nMufindi             0.9%\nKondoa              0.9%\nMwanga              0.9%\nSumbawanga Rural    0.9%\nIlala               0.9%\nBukoba Rural        0.8%\nBabati              0.8%\nGeita               0.8%\nMbeya Rural         0.8%\nMeatu               0.8%\nRufiji              0.8%\nSiha                0.7%\nTunduru             0.7%\nBunda               0.7%\nNkasi               0.7%\nMtwara Rural        0.7%\nKorogwe             0.7%\nMuleba              0.7%\nKishapu             0.7%\nBiharamulo          0.7%\nKilwa               0.7%\nMpwapwa             0.7%\nUrambo              0.7%\nMusoma Rural        0.6%\nLindi Rural         0.6%\nDodoma Urban        0.6%\nKongwa              0.6%\nManyoni             0.6%\nUkerewe             0.6%\nChamwino            0.6%\nKilolo              0.6%\nMissungwi           0.6%\nMuheza              0.6%\nIgunga              0.6%\nUyui                0.6%\nSengerema           0.6%\nKaratu              0.5%\nLongido             0.5%\nMbulu               0.5%\nNachingwea          0.5%\nPangani             0.5%\nSimanjiro           0.5%\nChunya              0.5%\nKibaha              0.5%\nRuangwa             0.5%\nMkinga              0.5%\nTandahimba          0.5%\nHanang              0.5%\nHandeni             0.4%\nMisenyi             0.4%\nChato               0.4%\nIleje               0.4%\nBahi                0.4%\nNewala              0.4%\nKisarawe            0.4%\nRorya               0.4%\nTemeke              0.4%\nTarime              0.4%\nKiteto              0.3%\nNgorongoro          0.3%\nShinyanga Urban     0.3%\nMonduli             0.3%\nSumbawanga Urban    0.3%\nSikonge             0.3%\nNanyumbu            0.3%\nKilindi             0.3%\nSingida Urban       0.3%\nLiwale              0.3%\nTabora Urban        0.3%\nIlemela             0.2%\nMafia               0.2%\nMtwara Urban        0.2%\nTanga               0.2%\nKinondoni           0.2%\nMorogoro Urban      0.2%\nBukoba Urban        0.2%\nMoshi Urban         0.1%\nSongea Urban        0.1%\nKigoma Urban        0.1%\nArusha Urban        0.1%\nLindi Urban         0.0%\nNyamagana           0.0%\nName: lga, dtype: object"
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual[\"lga\"].fillna(\"missing\", inplace=True)\n",
    "visual[\"lga\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "\n",
    "for df in together:\n",
    "    df.drop([\"region\", \"lga\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next `scheme_management`\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropping following columns because they are similar in look and feel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_cols = ['extraction_type', 'extraction_type_group']\n",
    "for df in together:\n",
    "    df.drop(selected_cols, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sanitizing `null` values\n",
    "\n",
    "1. For boolean columns: -> fill with median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# replace boolean cols with median values\n",
    "data[\"public_meeting\"].fillna(data[\"public_meeting\"].median(), inplace=True)\n",
    "data[\"permit\"].fillna(data[\"permit\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. For string/object values\n",
    "\n",
    "Reference: https://stackoverflow.com/a/60753938/10582056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nan_cols = ['scheme_management']\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value = 'missing')\n",
    "data[nan_cols] = imputer.fit_transform(data[nan_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. For numeric columns\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"amount_tsh\"] = data[\"amount_tsh\"].apply(lambda x: np.log(round(x)) if round(x) > 0 else 0)\n",
    "data[\"population\"] = data[\"population\"].apply(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. For `gps_height`, fill with reference data\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/heights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"gps_height\"].replace(to_replace=0, value=np.nan, inplace=True)\n",
    "data[\"gps_height\"] = data[\"gps_height\"].fillna(fill_heights[\"gps_height\"])\n",
    "data[\"gps_height\"].fillna(value=data[\"gps_height\"].mean(), inplace=True)\n",
    "\n",
    "assert (data[\"gps_height\"].isnull().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Fill missing `latitude` and `longitude` data\n",
    "\n",
    "Because geocode from google requires payment, this alternative is suitable\n",
    "\n",
    "Reference: https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_geo = data.groupby(['region_code'])[['latitude', 'longitude']].median()\n",
    "\n",
    "def geo_update(row, df_geo):\n",
    "    row['longitude'] = df_geo.loc[row['region_code']]['longitude']\n",
    "    row['latitude'] = df_geo.loc[row['region_code']]['latitude']\n",
    "    return row\n",
    "\n",
    "data.loc[data['longitude']== 0, ['longitude', 'latitude']] \\\n",
    "    = data[data['longitude']==0].apply(\n",
    "        geo_update,\n",
    "        df_geo=data_geo,\n",
    "        axis=1)[['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "7. Fill missing `subvillage`\n",
    "\n",
    "Reference: https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_subvillage = data.groupby(['region_code'])['subvillage'].agg(pd.Series.mode)\n",
    "\n",
    "def subvillage_update(row, df_subvillage):\n",
    "    row['subvillage'] = df_subvillage[row['region_code']]\n",
    "    return row\n",
    "\n",
    "data.loc[data['subvillage'].isnull(), ['subvillage']] = \\\n",
    "    data[data['subvillage'].isnull()].apply(\n",
    "        subvillage_update,\n",
    "        df_subvillage=data_subvillage,\n",
    "        axis=1)[['subvillage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with `Latitude` and `Longitude`\n",
    "\n",
    "Reference: https://stackoverflow.com/a/31398615/10582056\n",
    "\n",
    "1. Find the haversine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_lat = data[\"latitude\"].mean()\n",
    "mean_long = data[\"longitude\"].mean()\n",
    "\n",
    "data[\"haversine_distance\"] = data.apply(lambda row: haversine((row[\"latitude\"], row[\"longitude\"]), (mean_lat, mean_long), unit=Unit.KILOMETERS), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert `latitude`, `longitude` to `x_coordinate`, `y_coordinate` and `z_coordinate`\n",
    "\n",
    "Reference: https://heartbeat.fritz.ai/working-with-geospatial-data-in-machine-learning-ad4097c7228d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['x_coordinate'] = np.cos(data['latitude']) * np.cos(data['longitude'])\n",
    "data['y_coordinate'] = np.cos(data['latitude']) * np.sin(data['longitude'])\n",
    "data['z_coordinate'] = np.sin(data['latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do clustering with DBSCAN\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.2, min_samples=200)\n",
    "data[\"location_cluster\"] = db.fit_predict(data[[\"latitude\", \"longitude\"]])\n",
    "\n",
    "print(\"Clustering complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shorten and combine following columns\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this comes at the expense of reduced information\n",
    "# so might be commented out in future if necessary\n",
    "\n",
    "# Shorten and combine\n",
    "cols_100 = [[\"subvillage\", 4, 113],[\"scheme_name\", 5, 65], [\"ward\", 5, 117], [\"wpt_name\", 5, 57]]\n",
    "cols_200 = [[\"subvillage\", 4, 67],[\"scheme_name\", 5, 40], [\"ward\", 5, 87], [\"wpt_name\", 5, 30]]\n",
    "\n",
    "# cols_1000 includes more features at the expense of added complexity\n",
    "cols_1000 = [[\"subvillage\", 10, 11],[\"scheme_name\", 10, 10], [\"ward\", 5, 27], [\"wpt_name\", 10, 7]]\n",
    "combined = \"other\"\n",
    "\n",
    "for col, chars, threshold in cols_100:\n",
    "    # Missing values to combined group\n",
    "    data.loc[data[col].isnull() | data[col].isin([\"0\", \"-\", \"_\"]), col] = col + \"_\" + combined\n",
    "    # Lowercase and shorten\n",
    "    data[col] = data[col].map(lambda x: x[:chars].lower())\n",
    "    # Combine lower than threshold\n",
    "    data.loc[data[col].isin(data[col].value_counts()[data[col].value_counts() < threshold].index), col] = col + \"_\" + combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Drop unnecessary / similar columns\n",
    "\n",
    "Reference:\n",
    "1. https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb\n",
    "2. https://github.com/sagol/pumpitup/blob/main/oof_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# similar_cols = ['scheme_management', 'quantity_group', 'water_quality',\n",
    "#                 'region_code', 'payment_type', b'extraction_type',\n",
    "#                 'waterpoint_type_group', 'date_recorded', 'recorded_by']\n",
    "\n",
    "similar_cols = ['date_recorded', 'recorded_by', \"latitude\", \"longitude\"]\n",
    "\n",
    "data.drop(similar_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data types in `data` are mixed. So transform\n",
    "\n",
    "1. Some columns are in int format, but they are just categories -> convert them to string\n",
    "\n",
    "Reference: https://github.com/villeheilala/pumpitup/blob/master/pumpitup_preprocess.ipynb\n",
    "\n",
    "2. computable `numeric` and `boolean`(=[`public_meeting`, `permit`]) types to `float64`\n",
    "\n",
    "3. string columns 'category' for quick transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "convert = [\"district_code\", \"construction_year\", \"region_code\", \"location_cluster\", \"num_private\"]\n",
    "for col in convert:\n",
    "    data[col] = data[col].map(lambda x: str(x))\n",
    "\n",
    "# numeric columns\n",
    "numeric_columns = [\"public_meeting\", \"permit\"] + [col for col in data.columns if data[col].dtype not in [object, \"category\"]]\n",
    "\n",
    "# convert to float64\n",
    "for col in numeric_columns:\n",
    "    data[col] = data[col].astype(\"float64\")\n",
    "\n",
    "categorical_columns = [col for col in data.columns if col not in numeric_columns]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check if numeric columns follows Gaussian pattern\n",
    "if true: use `StandardScalar` else use `MinMaxScalar`\n",
    "\n",
    "Reference: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# qqplot(data[\"gps_height\"], line='s')\n",
    "# pyplot.hist(data[\"gps_height\"])\n",
    "# pyplot.show()\n",
    "\n",
    "def is_gaussian(feature, alpha):\n",
    "    stat, p = shapiro(data[feature])\n",
    "    print('%s: statistics=%.3f, p=%.3f, %s' % (feature, stat, p, 'yes' if p > alpha else 'no'))\n",
    "\n",
    "for column in numeric_columns:\n",
    "    is_gaussian(column, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Doing standardisation with `MinMax Scalar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "standard_cols = [\n",
    "    'amount_tsh',\n",
    "    'gps_height',\n",
    "    'population',\n",
    "    'haversine_distance',\n",
    "    'x_coordinate',\n",
    "    'y_coordinate',\n",
    "    'z_coordinate'\n",
    "]\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "data[standard_cols] = scalar.fit_transform(data[standard_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Make all strings to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    data[col] = data[col].apply(lambda x: x.lower(), convert_dtype=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply CatBoost\n",
    "\n",
    "The target labels should be numbers rather than strings. So encode them first\n",
    "\n",
    "Reference: https://stackoverflow.com/a/52061440/10582056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels[\"status_group\"] =  labels[\"status_group\"].astype(\"category\")\n",
    "label_dict = dict(enumerate(labels[\"status_group\"].cat.categories))\n",
    "\n",
    "labels[\"status_group\"] =  labels[\"status_group\"].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# size = train.shape[0]\n",
    "size = 200\n",
    "\n",
    "target = labels[\"status_group\"].values.ravel()\n",
    "\n",
    "train = data[data.type.eq(\"train\")].drop(\"type\", axis=1)\n",
    "test = data[data.type.eq(\"test\")].drop(\"type\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train.head(size),\n",
    "    target[:size],\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = target[:size],\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "print(\"Good to go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df = visual\n",
    "# col_details = []\n",
    "# for col in df.columns:\n",
    "#     if df[col].dtype in [\"category\", object]:\n",
    "#         col_details.append((col, df[col].dtype, df[col].nunique(), list(df[col].unique())))\n",
    "# col_details.sort(key=lambda x: 1 / x[-2])\n",
    "#\n",
    "# temp = pd.DataFrame(col_details, columns=[\"Column\", \"Dtype\", \"N_Unique\", \"Unique_vals\"])\n",
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyper parameter tuning for catboost\n",
    "\n",
    "Reference :\n",
    "1. https://stats.stackexchange.com/a/431105\n",
    "2. https://stats.stackexchange.com/a/457445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = [col for col in train.columns if data[col].dtype in (\"category\", object)]\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\":[800, 1000, 1200, 1500, 1700], # iterations\n",
    "    \"max_depth\": [5, 8, 10, 12, 15],\n",
    "    \"learning_rate\": [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7],\n",
    "    \"max_ctr_complexity\": [3, 7, 11, 15], # <16\n",
    "    \"od_wait\": [50, 100, 300, 500, 700, 1000],\n",
    "    \"od_type\": [\"IncToDec\", \"Iter\"],\n",
    "    \"leaf_estimation_backtracking\": ['AnyImprovement'], # Armijo - GPU only\n",
    "    # \"posterior_sampling\": [True, False],\n",
    "    \"auto_class_weights\": [\"Balanced\", \"SqrtBalanced\"],\n",
    "    \"leaf_estimation_method\": [\"Newton\", \"Gradient\"]\n",
    "}\n",
    "\n",
    "# scoring = {\n",
    "#     'accuracy': make_scorer(accuracy_score),\n",
    "#     'precision': make_scorer(precision_score, average = 'macro'),\n",
    "#     'recall': make_scorer(recall_score, average = 'macro'),\n",
    "#     'f1_macro': make_scorer(f1_score, average = 'macro'),\n",
    "#     'f1_weighted': make_scorer(f1_score, average = 'weighted'),\n",
    "#     # 'roc_auc': make_scorer(roc_auc_score, average='macro', multi_class=\"ovo\")\n",
    "#     'QUADRATIC_WEIGHT_SCORER': make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "# }\n",
    "\n",
    "catboost = CatBoostClassifier(\n",
    "    cat_features=cat_features,\n",
    "    task_type=\"GPU\",\n",
    "    random_state=42,\n",
    "    loss_function=\"MultiClass\",\n",
    "    class_names=[0, 1, 2],\n",
    "    allow_writing_files=False,\n",
    "    # thread_count=2,\n",
    "    nan_mode=\"Forbidden\",\n",
    "    fold_permutation_block=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hrsv = HalvingRandomSearchCV(\n",
    "    estimator=catboost,\n",
    "    param_distributions=grid,\n",
    "    # scoring=make_scorer(cohen_kappa_score, weights='quadratic'),\n",
    "    scoring=make_scorer(f1_score, average = 'weighted'),\n",
    "    # scoring=scoring,\n",
    "    cv=2,\n",
    "    error_score='raise',\n",
    "    refit=False,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hrsv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(hrsv.best_params_)\n",
    "print(hrsv.best_score_)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### for 100 rows\n",
    "\n",
    "{'od_wait': 100, 'od_type': 'IncToDec', 'n_estimators': 1200, 'max_depth': 10, 'max_ctr_complexity': 1, 'learning_rate': 0.5, 'l2_leaf_reg': 5}\n",
    "0.562962962962963\n",
    "\n",
    "{'od_wait': 300, 'od_type': 'IncToDec', 'n_estimators': 1000, 'max_depth': 15, 'max_ctr_complexity': 7, 'learning_rate': 1, 'l2_leaf_reg': 7}\n",
    "0.562962962962963\n",
    "\n",
    "{'od_wait': 300, 'od_type': 'IncToDec', 'n_estimators': 1000, 'max_depth': 15, 'max_ctr_complexity': 7, 'learning_rate': 1, 'l2_leaf_reg': 7}\n",
    "0.5888888888888889\n",
    "\n",
    "{'posterior_sampling': False, 'od_wait': 100, 'od_type': 'IncToDec', 'n_estimators': 1500, 'max_depth': 8, 'max_ctr_complexity': 3, 'learning_rate': 0.1, 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 1}\n",
    "0.6562289562289562\n",
    "\n",
    "{'posterior_sampling': True, 'od_wait': 100, 'od_type': 'Iter', 'n_estimators': 1000, 'max_depth': 8, 'max_ctr_complexity': 15, 'learning_rate': 0.1, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 1, 'auto_class_weights': 'SqrtBalanced'}\n",
    "0.5888888888888889\n",
    "\n",
    "{'posterior_sampling': False, 'od_wait': 1000, 'od_type': 'IncToDec', 'n_estimators': 1700, 'max_depth': 12, 'max_ctr_complexity': 3, 'learning_rate': 0.3, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 5, 'auto_class_weights': 'SqrtBalanced'}\n",
    "0.5577584732407249\n",
    "\n",
    "\n",
    "#### for 25 rows\n",
    "\n",
    "{'posterior_sampling': True, 'od_wait': 100, 'od_type': 'Iter', 'n_estimators': 1000, 'max_depth': 8, 'max_ctr_complexity': 15, 'learning_rate': 0.1, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 3, 'auto_class_weights': 'SqrtBalanced'}\n",
    "0.6\n",
    "\n",
    "{'od_wait': 500, 'od_type': 'IncToDec', 'n_estimators': 1000, 'max_depth': 12, 'max_ctr_complexity': 3, 'learning_rate': 0.7, 'leaf_estimation_method': 'Newton', 'leaf_estimation_backtracking': 'AnyImprovement', 'l2_leaf_reg': 3, 'auto_class_weights': 'Balanced'}\n",
    "0.462962962962963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# catboost = CatBoostClassifier(\n",
    "#     posterior_sampling=False,\n",
    "#     od_wait=1000,\n",
    "#     od_type=\"IncToDec\",\n",
    "#     n_estimators=1700,\n",
    "#     max_depth=12,\n",
    "#     max_ctr_complexity=3,\n",
    "#     learning_rate=0.3,\n",
    "#     leaf_estimation_method=\"Newton\",\n",
    "#     leaf_estimation_backtracking=\"AnyImprovement\",\n",
    "#     l2_leaf_reg=5,\n",
    "#     auto_class_weights='SqrtBalanced'\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}